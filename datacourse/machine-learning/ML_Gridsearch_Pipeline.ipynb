{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fetch_california_housing()['data']\n",
    "y = fetch_california_housing()['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5943141338604155\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('regressor', Ridge())\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('regressor',\n",
       "   Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "         normalize=False, random_state=None, solver='auto', tol=0.001))],\n",
       " 'verbose': False,\n",
       " 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'regressor': Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "       normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__with_mean': True,\n",
       " 'scaler__with_std': True,\n",
       " 'regressor__alpha': 1.0,\n",
       " 'regressor__copy_X': True,\n",
       " 'regressor__fit_intercept': True,\n",
       " 'regressor__max_iter': None,\n",
       " 'regressor__normalize': False,\n",
       " 'regressor__random_state': None,\n",
       " 'regressor__solver': 'auto',\n",
       " 'regressor__tol': 0.001}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('regressor',\n",
       "                                        Ridge(alpha=1.0, copy_X=True,\n",
       "                                              fit_intercept=True, max_iter=None,\n",
       "                                              normalize=False,\n",
       "                                              random_state=None, solver='auto',\n",
       "                                              tol=0.001))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=2,\n",
       "             param_grid={'regressor__al...3240e-03, 8.85866790e-03,\n",
       "       1.83298071e-02, 3.79269019e-02, 7.84759970e-02, 1.62377674e-01,\n",
       "       3.35981829e-01, 6.95192796e-01, 1.43844989e+00, 2.97635144e+00,\n",
       "       6.15848211e+00, 1.27427499e+01, 2.63665090e+01, 5.45559478e+01,\n",
       "       1.12883789e+02, 2.33572147e+02, 4.83293024e+02, 1.00000000e+03])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"regressor__alpha\": np.logspace(-3, 3, 20)\n",
    "}\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=2, verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regressor__alpha': 12.742749857031322}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6053956962874548"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's cache the pipeline for future re-use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory='/tmp/tmp9nm015m5',\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('regressor',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cachedir = mkdtemp()\n",
    "pipe_cache = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('regressor', Ridge())\n",
    "], memory=cachedir)\n",
    "pipe_cache.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's use a different approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('grid_search',\n",
       "                 GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                              estimator=Ridge(alpha=1.0, copy_X=True,\n",
       "                                              fit_intercept=True, max_iter=None,\n",
       "                                              normalize=False,\n",
       "                                              random_state=None, solver='auto',\n",
       "                                              tol=0.001),\n",
       "                              iid='warn', n_jobs=2,\n",
       "                              param_grid={'alpha': array([1.00000000e-03...90e-03,\n",
       "       1.83298071e-02, 3.79269019e-02, 7.84759970e-02, 1.62377674e-01,\n",
       "       3.35981829e-01, 6.95192796e-01, 1.43844989e+00, 2.97635144e+00,\n",
       "       6.15848211e+00, 1.27427499e+01, 2.63665090e+01, 5.45559478e+01,\n",
       "       1.12883789e+02, 2.33572147e+02, 4.83293024e+02, 1.00000000e+03])},\n",
       "                              pre_dispatch='2*n_jobs', refit=True,\n",
       "                              return_train_score=False, scoring=None,\n",
       "                              verbose=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"alpha\": np.logspace(-3, 3, 20)\n",
    "}\n",
    "grid_search = GridSearchCV(Ridge(), param_grid, cv=5, n_jobs=2, verbose=1)\n",
    "\n",
    "pipe2 = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('grid_search', grid_search)\n",
    "])\n",
    "pipe2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'grid_search': GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "              estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                              max_iter=None, normalize=False, random_state=None,\n",
       "                              solver='auto', tol=0.001),\n",
       "              iid='warn', n_jobs=2,\n",
       "              param_grid={'alpha': array([1.00000000e-03, 2.06913808e-03, 4.28133240e-03, 8.85866790e-03,\n",
       "        1.83298071e-02, 3.79269019e-02, 7.84759970e-02, 1.62377674e-01,\n",
       "        3.35981829e-01, 6.95192796e-01, 1.43844989e+00, 2.97635144e+00,\n",
       "        6.15848211e+00, 1.27427499e+01, 2.63665090e+01, 5.45559478e+01,\n",
       "        1.12883789e+02, 2.33572147e+02, 4.83293024e+02, 1.00000000e+03])},\n",
       "              pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "              scoring=None, verbose=1)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 26.366508987303554}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.named_steps['grid_search'].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Dimension Reduction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 202 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=2)]: Done 500 out of 500 | elapsed:    8.6s finished\n"
     ]
    }
   ],
   "source": [
    "cachedir = mkdtemp()\n",
    "pipe_3 = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('dim-red', PCA()), \n",
    "    ('regressor', Ridge())\n",
    "], memory=cachedir)\n",
    "\n",
    "param_grid = {\n",
    "    'dim-red__n_components': [2, 3, 4, 5, 6], \n",
    "    'regressor__alpha': np.logspace(-3, 3, 20)\n",
    "}\n",
    "grid_search = GridSearchCV(pipe_3, param_grid, cv=5, n_jobs=2, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dim-red__n_components': 6, 'regressor__alpha': 26.366508987303554}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4782182317645793"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 132 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=2)]: Done 500 out of 500 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory='/tmp/tmpuqm7_6yv',\n",
       "                                      steps=[('scaler',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('dim-red',\n",
       "                                              PCA(copy=True,\n",
       "                                                  iterated_power='auto',\n",
       "                                                  n_components=None,\n",
       "                                                  random_state=None,\n",
       "                                                  svd_solver='auto', tol=0.0,\n",
       "                                                  whiten=False)),\n",
       "                                             ('regressor',\n",
       "                                              Ridge(alpha=1.0, copy_X=True,\n",
       "                                                    fit_interce...\n",
       "       2.67384162e+02, 2.86606762e+02, 3.07211300e+02, 3.29297126e+02,\n",
       "       3.52970730e+02, 3.78346262e+02, 4.05546074e+02, 4.34701316e+02,\n",
       "       4.65952567e+02, 4.99450512e+02, 5.35356668e+02, 5.73844165e+02,\n",
       "       6.15098579e+02, 6.59318827e+02, 7.06718127e+02, 7.57525026e+02,\n",
       "       8.11984499e+02, 8.70359136e+02, 9.32930403e+02, 1.00000000e+03])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cachedir = mkdtemp()\n",
    "pipe_4 = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('dim-red', PCA()), \n",
    "    ('regressor', Ridge())\n",
    "], memory=cachedir)\n",
    "\n",
    "param_grid = {\n",
    "    'dim-red__n_components': range(1, 9), \n",
    "    'regressor__alpha': np.logspace(-3, 3, 200)\n",
    "}\n",
    "randomized_grid_search = RandomizedSearchCV(pipe_4, param_grid, cv=5, n_jobs=2, verbose=1, n_iter=100)\n",
    "randomized_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5941268031952003"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_grid_search.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
